{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv as csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('wine-reviews\\winemag-data_first150k.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load the wine dataset. This dataset has wine data from 49 countrues with 2 attributes. We will be using the points and price of the wine to classift the country the wine is from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1           1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4           4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the columns that contain the country, points ,and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "country=train.values[:,1]\n",
    "points=train.values[:,4]\n",
    "price=train.values[:,5]\n",
    "\n",
    "x=np.array(train.values[:,4:6])\n",
    "y=[]\n",
    "for g in range (100):\n",
    "    y.append(np.array(train.values[g,4:6]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are plotting he data for the top 3 countries to show that there is a lot of overlap among the datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for h in range(1000):\n",
    "    #print(country[h])\n",
    "    if country[h]==str(\"US\"):\n",
    "         plt.plot(points[h],price[h],'bo')\n",
    "    if country[h]==str(\"Italy\"):\n",
    "         plt.plot(points[h],price[h],'ro')\n",
    "    if country[h]==str(\"France\"):\n",
    "         plt.plot(points[h],price[h],'go')    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US', 'Italy', 'France', 'Spain', 'Chile', 'Argentina', 'Portugal', 'Australia', 'New Zealand', 'Austria', 'Germany', 'South Africa', 'Greece', 'Israel', 'Hungary', 'Canada', 'Romania', 'Slovenia', 'Uruguay', 'Croatia', 'Bulgaria', 'Moldova', 'Mexico', 'Turkey', 'Georgia', 'Lebanon', 'Cyprus', 'Brazil', 'Macedonia', 'Serbia', 'Morocco', 'England', 'Luxembourg', 'India', 'Lithuania', 'Czech Republic', nan, 'Ukraine', 'Switzerland', 'Bosnia and Herzegovina', 'South Korea', 'China', 'Slovakia', 'Egypt', 'Albania', 'Japan', 'Montenegro', 'Tunisia', 'US-France']\n",
      "[62397, 23478, 21098, 8268, 5816, 5631, 5322, 4957, 3320, 3057, 2452, 2258, 884, 630, 231, 196, 139, 94, 92, 89, 77, 71, 63, 52, 43, 37, 31, 25, 16, 14, 12, 9, 9, 8, 8, 6, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(country)\n",
    "#print(counts)\n",
    "common_country=[]\n",
    "country_freq=[]\n",
    "f=counts.most_common(49)\n",
    "for j in range (49):\n",
    "    common_country.append(f[j][0])\n",
    "    country_freq.append(f[j][1])\n",
    "    \n",
    "print(common_country)\n",
    "print(country_freq)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are determining the most commong countries in our dataset and the frequency of how many times each country appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 150930)\n"
     ]
    }
   ],
   "source": [
    "data=np.vstack((points,price))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that are used to fold the data and to perform k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folds(data,k,split): #split is what size split you want\n",
    "    #n = np.zeros((k,split,data.shape[1]))\n",
    "    n = []\n",
    "    num1 = 0\n",
    "    num2 = split\n",
    "    for i in range(k-1):\n",
    "        n.append(data[num1:num2])\n",
    "        num1 = num2\n",
    "        num2 = num2 + split\n",
    "    n.append(data[num1:])\n",
    "    return n\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "def cross_validation_winegaus(k, splitdata, splitlabels):\n",
    "    z = np.zeros(k)\n",
    "    final = [];\n",
    "    for i in range(k):\n",
    "        training_data = np.concatenate(np.delete(splitdata, i,0),axis=0)\n",
    "        train_labels = np.concatenate(np.delete(splitlabels, i,0),axis=0)\n",
    "        test_data = splitdata[i]\n",
    "        test_labels = splitlabels[i]    \n",
    "        model.fit(training_data.astype(float),train_labels.astype(float))\n",
    "        predicted= model.predict(test_data.astype(float))\n",
    "        acc = predicted-test_labels.astype(float)\n",
    "        z[i]=np.count_nonzero(acc)/acc.size\n",
    "        final = np.concatenate((final,predicted))\n",
    "    return np.mean(z),final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_country=np.zeros(150930)           \n",
    "for m in range (150930):\n",
    "    for n in range(49):    \n",
    "        if country[m] == common_country[n]:\n",
    "            #np.concatenate((new_country,np.array([l])),axis=0)\n",
    "            #np.append(new_country,l)\n",
    "            all_country[m]=n\n",
    "            \n",
    "for x in range(data.shape[1]):\n",
    "    if math.isnan(data[0][x]):\n",
    "                data[0][x]=0\n",
    "    if math.isnan(data[1][x]):\n",
    "                data[1][x]=0            \n",
    "\n",
    "train_fold=folds(np.transpose(data),5,30186)\n",
    "test_fold=folds(all_country,5,30186)\n",
    "# for h in range(5):\n",
    "#     print(train_fold[h].shape)\n",
    "#     print(test_fold[h].shape)\n",
    "    \n",
    "splitdata=np.asarray([train_fold[0],train_fold[1],train_fold[2],train_fold[3],train_fold[4]])  \n",
    "splitlabels=np.asarray([test_fold[0],test_fold[1],test_fold[2],test_fold[3],test_fold[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have performed k-fold cross validation for classification iwth k=5. In this case, there were 4 folds used for testing and 1 fold used for testing. With this implementation each data sample was only used once for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the Sci-kit learn GuassianNB Bayes function. We will plug our training data into model.fit() function and we will make predictions using the model.predict() function. The way GaussianNB works is that it iterates through every possible class of the output and calculates the mean and the standard deviation of ech feature of the training data that corresponds to that class. The mean is given by the sum of the elements divided by the total number of elements in the training set. The standard deviation is is given by taking each data sample and subtracting the mean of that feature and taking the square of the result. This value is summed for all of the data samples for each feature and is then  divided by the number of training samples per feature. This gives us the variance. Finally we take the square root of the data to obtain the standard deviation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the mean and standard deviation for each feature in the training data we plug value of the test data into the Gaussian distribution equation in order to determine the probability that each test sample belongs to a class. \n",
    "\\begin{equation*}\n",
    "N(\\mu,sigma^2) = \\Bigg[ \\frac{1}{(\\sqrt {2 \\pi*sigma^2})} \\exp \\; \\bigg[ -\\frac{1}{2} \\bigg(\\frac{\\pmb x - \\mu}{2*sigma^2} \\bigg)^2 \\bigg] \\Bigg]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above equation the mu represents the mean and the sigma^2 represents the standard deviation. x represents the sample that we are testing. We will plug into this equation for each test sample to obtain the probability that it belongs to each class. The feature with the greatest probability will be the prediction for the data sample.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6156628900814947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "\n",
    "acc,l=cross_validation_winegaus(5,splitdata,splitlabels)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is 0.616. This is relatively low since the amount of features in our data was relatively low as well. we only had 2 features in the data with numerical values that were usable. This made it difficult for our alogrithm to be successful. Also it may be possible for their to be little correlation between the data and the output value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.74998798 71.780092   73.49369608 69.75108853 64.58596974 67.27561712\n",
      " 73.85174746 59.56344563 57.30331325 71.87602224 75.72593801 64.97962799\n",
      " 65.54072398 76.68730159 63.98268398 74.88265306 64.52517986 88.23404255\n",
      " 60.75       81.59550562 65.7012987  58.92957746 84.76190476 88.09615385\n",
      " 77.79069767 74.48648649 61.22580645 79.88       58.875      87.71428571\n",
      " 81.33333333 92.88888889 58.         87.625      84.25       85.83333333\n",
      "  0.         84.6        45.         84.75       81.5        54.66666667\n",
      " 56.33333333 83.66666667 88.         85.         82.          0.\n",
      "  0.        ]\n",
      "[26.9140183  24.35480024 26.16181629 20.84059023 14.9485901  16.66116143\n",
      " 16.4485156  21.84890054 14.95813253 19.73110893 32.6276509  15.70416298\n",
      " 16.55769231 26.77142857 32.37229437 28.53571429 10.07913669 24.18085106\n",
      " 16.81521739 21.25842697  9.45454545 11.3943662  29.0952381  24.80769231\n",
      " 17.46511628 21.2972973  11.41935484 19.4        10.5        24.28571429\n",
      " 18.33333333 42.22222222 27.11111111 13.875      10.         18.\n",
      "  0.         13.         12.25       12.75       13.5        18.\n",
      " 10.33333333  0.         20.         24.         10.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "sep_country_points=np.zeros(49)\n",
    "sep_country_price=np.zeros(49)\n",
    "#all_country_points=np.zeros((49,62397))\n",
    "#all_country_price=np.zeros((49,62397))\n",
    "import math\n",
    "\n",
    "for t in range (120000):\n",
    "    for l in range(49):    \n",
    "        if country[t] == common_country[l]:\n",
    "            sep_country_points[l]=sep_country_points[l] + points[t]\n",
    "            #for k in range (62397):\n",
    "               # if all_country_points[l][k] ==0:\n",
    "               # all_country_points[l][k] = points[t]\n",
    "               # break\n",
    "                \n",
    "            if math.isnan(price[t]):\n",
    "                price[t]=0\n",
    "               \n",
    "            sep_country_price[l]=sep_country_price[l] + price[t]\n",
    "          #  for k in range (62397): \n",
    "          #  if all_country_price[l][k] ==0:\n",
    "          #      all_country_price[l][k] = price[t]\n",
    "          #      break\n",
    "            #print(price[t],type(price[t]))\n",
    "    \n",
    "\n",
    "sep_country_points=sep_country_points/country_freq\n",
    "print(sep_country_points)\n",
    "\n",
    "sep_country_price=sep_country_price/country_freq\n",
    "print(sep_country_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.42527393 15.22453163 14.32616666 15.34535308 19.05484877 16.84819764\n",
      " 13.27768916 23.537484   24.63230442 15.84756047 12.26798208 19.31128483\n",
      " 18.11355571 10.24453762 20.29045924 12.64748687 18.25276198  1.99694198\n",
      " 20.40903066  5.36353221 17.70546843 22.10963581  2.82682325  1.5598276\n",
      "  8.13197207 11.12345938 21.20257514  3.64321616 22.29689142  1.09730654\n",
      "  7.28900745  1.2862041  23.68778401  3.4255474   0.4330127   0.68718427\n",
      "  1.          1.0198039  31.81980515  2.04633819  0.5        22.31757321\n",
      " 23.08839696  0.47140452  1.          1.          1.          1.\n",
      "  1.        ]\n",
      "[0.02076861 0.03220785 0.03521383 0.0502059  0.05069766 0.05439511\n",
      " 0.05559374 0.06639041 0.06712274 0.0803393  0.115354   0.08339604\n",
      " 0.13685913 0.20614153 0.37435251 0.38156307 0.2692801  0.50719138\n",
      " 0.42752088 0.48873176 0.35040877 0.40060458 0.67958015 0.69070327\n",
      " 0.63731114 0.7586848  0.60693186 0.88090862 0.81009259 1.31707778\n",
      " 1.23603308 2.1659543  1.73561104 1.31695672 1.11803399 1.73205081\n",
      " 1.         1.61245155 1.75       1.78535711 1.83711731 2.44948974\n",
      " 1.85592145 1.         3.16227766 3.46410162 2.23606798 1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "std_country_points=np.zeros(49)\n",
    "std_country_price=np.zeros(49)\n",
    "for t in range (120000):\n",
    "    for l in range(49):    \n",
    "        if country[t] == common_country[l]:\n",
    "            std_country_points[l]=std_country_points[l] + math.pow((points[t]-sep_country_points[l]),2)\n",
    "            if math.isnan(price[t]):\n",
    "                price[t]=0\n",
    "               \n",
    "            std_country_price[l]=std_country_price[l] + math.pow((points[t]-sep_country_price[l]),2)\n",
    "            \n",
    "std_country_points=np.sqrt(std_country_points/country_freq)          \n",
    "std_country_price=np.sqrt(sep_country_price/country_freq)            \n",
    "\n",
    "for r in range(49):\n",
    "    if std_country_points[r] ==0:\n",
    "        std_country_points[r]=1;\n",
    "    if std_country_price[r] ==0:\n",
    "        std_country_price[r]=1;\n",
    "print(std_country_points)\n",
    "print(std_country_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine Classification Dataset 1 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv(\"wine-reviews/winemag-data_first150k.csv\")\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = file.values[:,1]\n",
    "score = file.values[:,4]\n",
    "price = file.values[:,5]\n",
    "variety = file.values[:,9]\n",
    "totalinput = file.values[:,4:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wine classification used only contains 2 features that can be used.  Because of this, there seems to be a lack of correlation between the features and classification.  The error seen by kNN is very high.  Also, the kNN implementation has a time complexity of atleast O(N^2).  Because of this, the algorithm cannot take advantage of all 150k+ datapoints.  The implementation of kNN for this is using 2000 datapoints for one iteration of knn and 1000 datapoints to find the best k.  Becuase of these reasons, we decided to use another wine dataset to classify as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using k = 5 and 2000 total datapoints(1500 training, 500 test), the percent error is % 56.599999999999994 .\n"
     ]
    }
   ],
   "source": [
    "test = totalinput[:500]\n",
    "testans = country[:500]\n",
    "training = totalinput[500:2000]\n",
    "trainingans = country[500:2000]\n",
    "g = knn(5,training,test,trainingans)\n",
    "d = knnerror(g,testans)\n",
    "print(\"Using k = 5 and 2000 total datapoints(1500 training, 500 test), the percent error is %\",d*100,\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of k using crossvalidation is 20 and the error associated is % 52.5 .\n"
     ]
    }
   ],
   "source": [
    "foldsinput = totalinput[:1000]\n",
    "foldslabel = country[:1000]\n",
    "j = folds(foldsinput,5,200)\n",
    "t = folds(foldslabel,5,200)\n",
    "a,b = bestk([1,5,10,20,50],5,j,t)\n",
    "print(\"The best value of k using crossvalidation is\",a,\"and the error associated is %\",b*100,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine Classification Dataset 2 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv('wine.csv')\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total = file.values\n",
    "labels = file.values[:,0]\n",
    "data = file.values[:,1:]\n",
    "datat = data.T      #   -------PCA-------\n",
    "mdata = datat.mean(axis = 1)  #Find mean\n",
    "print(mdata.shape)\n",
    "mdatam = np.tile(mdata.reshape(datat.shape[0],1),[1,datat.shape[1]]) #Make mean meatrix that spans dataset\n",
    "center = datat - mdatam  #Center all the data by subtracting by mean\n",
    "U, s, v = np.linalg.svd(center) #Find singular value components\n",
    "Uusing = U[:,0:2] #Take top 2 eigenvectors\n",
    "x = Uusing.T@center #apply eigenvectors to centered data\n",
    "test = x[:,:40].T\n",
    "testlabels = labels[:40]\n",
    "traindata = x[:,40:].T\n",
    "trainlabels = labels[40:]\n",
    "plt.title(\"PCA Data Distribution\")\n",
    "plt.scatter(x.T[np.where(labels==1),0],x.T[np.where(labels==1),1],c='r',marker='o',label = '1')\n",
    "plt.scatter(x.T[np.where(labels==2),0],x.T[np.where(labels==2),1],c='g',marker='s',label = '2')\n",
    "plt.scatter(x.T[np.where(labels==3),0],x.T[np.where(labels==3),1],c='b',marker='s',label = '3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA, we are able to visualize the data being used with minor data being loss. While the data isn't perfectly seperable, there seems to be a correlation between the dataset and the labels.  PCA is used because it allows us to reduce the dimensionality of the data.  Normally, we use this in order to speed up an algorithm we are using.  In this case, we can use it to visualize the relationship between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k,train,test,trainanswer):\n",
    "    dist = np.zeros((train.shape[0],))\n",
    "    testans = np.zeros((test.shape[0],),dtype = object)\n",
    "    for g in range(testans.shape[0]):\n",
    "        for i in range(trainanswer.shape[0]):\n",
    "            dist[i] = np.linalg.norm(train[i] - test[g])\n",
    "        c = Counter(trainanswer[np.argsort(dist)][:k])\n",
    "        testans[g] = c.most_common(1)[0][0]\n",
    "    return testans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the generic knn algorithm being used for classification.  In order to classify using knn, you need to find the distance between your test point and each of the training data.  Then, find the k smallest distances' datapoints and their classification.  Finally, choose the most seen classification between the k datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnerror(testans,actualans):\n",
    "    error = 0\n",
    "    for i in range(testans.shape[0]):\n",
    "        if (testans[i] != actualans[i]):\n",
    "            error = error + 1;\n",
    "    error = error/(testans.shape[0])\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knnerror is used to find the error between the generated test classifiers and the actual labels.  Every classification error increases the error value by one.  It returns the percent error found by dividing the toal error and the total datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folds(data,k,split):\n",
    "    n = []\n",
    "    num1 = 0\n",
    "    num2 = split\n",
    "    for i in range(k-1):\n",
    "        n.append(data[num1:num2])\n",
    "        num1 = num2\n",
    "        num2 = num2 + split\n",
    "    n.append(data[num1:])\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folds is used to create folds that will be used in cross validation.  It takes in the data, how many folds you want, and the amount for each split.  If the splits do not divide evenly, the final split will contain an amount of data not equal to the split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validationknn(splitnum, splitdata, splitlabels,k):\n",
    "    z = np.zeros(splitnum)\n",
    "    final = [];\n",
    "    for i in range(splitnum):\n",
    "        training_data = np.concatenate(np.delete(splitdata, i,0),axis=0)\n",
    "        train_labels = np.concatenate(np.delete(splitlabels, i,0),axis=0)\n",
    "        test_data = splitdata[i]\n",
    "        test_labels = splitlabels[i]\n",
    "        y_tested = knn(k,training_data,test_data,train_labels)\n",
    "        z[i] = knnerror(y_tested,test_labels)\n",
    "        final = np.concatenate((final,y_tested))\n",
    "    return np.mean(z),final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is used to find the best value for k.  It uses the folds created by the folds function.  What the function does is perform knn multiple times where each fold becomes the test data once and the rest of the folds become the training data.  It computes the knnerror each time knn is run.  The output is the mean of all the error percentages and all the labels that the folds created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestk(k,splitnum,splitdata,splitlabels):\n",
    "    j = [];\n",
    "    for i in range(len(k)):\n",
    "        j.append((cross_validationknn(splitnum,splitdata,splitlabels,k[i]))[0])\n",
    "    error = min(j)\n",
    "    bestk = k[j.index(min(j))]\n",
    "    return bestk,error  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestk is used in conjunction with crossvalidation.  Bestk runs crossvalidation with different values of k(k in kNN) and chooses the k value with the least error.  It returns the best k value and the error associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN error using PCA is % 27.500000000000004 .\n"
     ]
    }
   ],
   "source": [
    "g = knn(5,traindata,test,trainlabels)\n",
    "d = knnerror(g,testlabels)\n",
    "print(\"kNN error using PCA is %\",d*100,\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test[np.where(g==1),0],test[np.where(g==1),1],c='r',marker='^')\n",
    "plt.scatter(test[np.where(g==2),0],test[np.where(g==2),1],c='g',marker='^')\n",
    "plt.scatter(test[np.where(g==3),0],test[np.where(g==3),1],c='b',marker='^')\n",
    "plt.scatter(traindata[np.where(trainlabels==1),0],traindata[np.where(trainlabels==1),1],c='r',marker='o')\n",
    "plt.scatter(traindata[np.where(trainlabels==2),0],traindata[np.where(trainlabels==2),1],c='g',marker='o')\n",
    "plt.scatter(traindata[np.where(trainlabels==3),0],traindata[np.where(trainlabels==3),1],c='b',marker='o')\n",
    "plt.title('PCA KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of k using crossvalidation is  1 and the error associated is % 34.53281853281853 .\n"
     ]
    }
   ],
   "source": [
    "j = folds(data,5,35)\n",
    "t = folds(labels,5,35)\n",
    "a,b = bestk([1,5,10,20,50],5,j,t)\n",
    "print(\"The best value of k using crossvalidation is \",a,\"and the error associated is %\",b*100,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ended up switching to a different wine dataset, as the first dataset (from kaggle), only had two features that were numerical and easily used for classification. This proved to be insufficient. So, we switched to a new dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-188-31d241994c46>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-188-31d241994c46>\"\u001b[1;36m, line \u001b[1;32m31\u001b[0m\n\u001b[1;33m    ''''''\u001b[0m\n\u001b[1;37m          \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "#This section is to show how only two features is insufficient at classifying wines by their country of origin\n",
    "'''\n",
    "wine = np.array(pd.read_csv('wine123.csv', header=None))\n",
    "#Get countries in wine\n",
    "count = 0\n",
    "countries = {}\n",
    "for i in range(len(wine)):\n",
    "    if wine[i,1] not in countries:\n",
    "        countries[wine[i,1]] = count\n",
    "        count +=  1\n",
    "        \n",
    "for i in range(len(wine)):\n",
    "    wine[i,1] = countries[wine[i,1]]\n",
    "\n",
    "wine_countries = wine[:,1]\n",
    "wine_features = np.vstack((wine[1::,4], wine[1::,5]))\n",
    "wine_features[1,0] = 0\n",
    "\n",
    "for i in range(len(wine_features)):\n",
    "    for j in range(len(wine_features[0])):\n",
    "        try:\n",
    "            wine_features[i,j] = float(wine_features[i,j])\n",
    "        except:\n",
    "            wine_features[i,j] = 0\n",
    "print(wine_countries.shape)\n",
    "print(wine_features)\n",
    "wine_svm = svm.LinearSVC(penalty='l2', loss='hinge', max_iter = 20000, tol=0.001, multi_class='ovr')\n",
    "\n",
    "wine_svm.fit(wine_features.transpose(), wine_countries)\n",
    "print(wine_svm.score(wine_features.transpose(), wine_countries))\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load new dataset\n",
    "wine = np.array(pd.read_csv('Wine.csv', header=None))\n",
    "wine_labels = wine[:,0]\n",
    "wine_features = wine[:,1::].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we had more success with one vs. Rest classification, that's the approach we will be taking here\n",
    "#Create class labels\n",
    "classone_labels = [1 if x == 1 else 0 for x in labels]\n",
    "\n",
    "classtwo_labels = [1 if x == 2 else 0 for x in labels]\n",
    "\n",
    "classthree_labels = [1 if x == 3 else 0 for x in labels]\n",
    "\n",
    "class_labels = [classone_labels, classtwo_labels, classthree_labels]\n",
    "\n",
    "#Normalize data\n",
    "\n",
    "for i in range(len(wine_features)):\n",
    "    feature = wine_features[i]\n",
    "    length = len(feature)\n",
    "    mean = np.mean(feature)\n",
    "    stdev = np.std(feature)\n",
    "    wine_features[i] = (feature - [mean]*length)/stdev    \n",
    "#Train SVMs\n",
    "wine_svms = []\n",
    "\n",
    "for i in range(0,3):\n",
    "    _svm = svm.LinearSVC(penalty='l2', loss='hinge', max_iter = 20000, tol=0.001, verbose=1)\n",
    "    _svm.fit(wine_features.transpose(), class_labels[i])\n",
    "    wine_svms.append(_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification. We'll be reusing the prediction function we defined earlier\n",
    "OVA_wine_predictions = []\n",
    "for i in range(len(wine_features[0])):\n",
    "    wine = wine_features[:,i]\n",
    "    prediction = getPrediction(wine.reshape(1,len(wine)), wine_svms, [1,2,3])\n",
    "    OVA_wine_predictions.append(prediction)\n",
    "\n",
    "#Calculate accuracy based on # of correct classifications\n",
    "correct = 0\n",
    "for i in range(len(OVA_wine_predictions)):\n",
    "    if OVA_wine_predictions[i] == wine_labels[i]:\n",
    "        correct += 1\n",
    "print(\"Accuracy: \" + str(correct/len(OVA_wine_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load new dataset\n",
    "wine = np.array(pd.read_csv('Wine.csv', header=None))\n",
    "wine_labels = wine[:,0]\n",
    "wine_features = wine[:,1::].transpose()\n",
    "\n",
    "#This section is to show how only two features is insufficient at clasisfyinh wine\n",
    "wine_svm = svm.LinearSVC(penalty='l2', loss='hinge', max_iter = 20000, tol=0.001, multi_class='ovr')\n",
    "\n",
    "wine_svm.fit(wine_features.transpose(), wine_labels)\n",
    "print(wine_svm.score(wine_features.transpose(), wine_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag Classification SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "flags = np.array(pd.read_csv('flags.data', header=None))\n",
    "#194 flags, 30 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_names = flags.transpose()[0]\n",
    "flag_features = flags.transpose()[1::]\n",
    "\n",
    "#We need to do a little preprocessing. Not every feature is a number.\n",
    "#Features 18 (mainhue), 29 (color in top left), and 30 (color in top right) are strings\n",
    "\n",
    "color_map = {'red' : 1, 'green' : 2, 'blue' : 3, 'gold' : 4, 'white' : 5, 'black' : 6, 'orange' : 7, 'brown' : 8}\n",
    "mainhue = flag_features[16]\n",
    "col_toplef = flag_features[-2]\n",
    "col_botrig = flag_features[-1]\n",
    "\n",
    "mainhue_num = [color_map[mainhue[i]] for i in range(len(mainhue))]\n",
    "ctl_num = [color_map[col_toplef[i]] for i in range(len(col_toplef))]\n",
    "cbr_num = [color_map[col_botrig[i]] for i in range(len(col_botrig))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the appropriate features in the data matrix\n",
    "flag_features[16] = mainhue_num\n",
    "flag_features[-2] = ctl_num\n",
    "flag_features[-1] = cbr_num\n",
    "\n",
    "#Standardize the features\n",
    "\n",
    "for i in range(len(flag_features)):\n",
    "    feature = flag_features[i]\n",
    "    length = len(feature)\n",
    "    mean = np.mean(feature)\n",
    "    stdev = np.std(feature)\n",
    "    flag_features[i] = (feature - [mean]*length)/stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will build a one vs. all multiclass classifier utilizing SVMs as the binary classifier\n",
    "#This requires the training of 193 SVM classifiers\n",
    "\n",
    "#Generate list of training labels \n",
    "#We're going to create an array of zeros with a single 1 at the position of each target flag\n",
    "#This is necessary since we're doing one vs all classification. The flag in question is 1, while everything else is a 0.\n",
    "training_labels = []\n",
    "for i in range(len(flag_names)):\n",
    "    temp = np.zeros(len(flag_features[0]))\n",
    "    temp[i] = 1\n",
    "    training_labels.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 193 SVM classifiers\n",
    "svms = []\n",
    "for labels in training_labels:\n",
    "    _svm = svm.LinearSVC(penalty='l2', loss='hinge', max_iter = 20000, tol=0.001)\n",
    "    _svm.fit(flag_features.transpose(), labels)\n",
    "    svms.append(_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The array of svms is our classifier\n",
    "def getPrediction(X, svms, labels):\n",
    "    confidences = []\n",
    "    for _svm in svms:\n",
    "        confidences.append(_svm.decision_function(X))\n",
    "    return labels[confidences.index(max(confidences))]# max(confidences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVA_flag_predictions = []\n",
    "for i in range(len(flag_features[0])):\n",
    "    flag = flag_features[:,i]\n",
    "    prediction = getPrediction(flag.reshape(1,len(flag)), svms, flag_names)\n",
    "    OVA_flag_predictions.append(prediction)\n",
    "    print(\"Predicted: \" + prediction + \"\\tActual: \" + flag_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try new attempt, one vs one classification\n",
    "#Train N(N-1)/2 binary classifiers\n",
    "#Certain flags are very similar - this might have more success\n",
    "#We are limited in the sense that each flag only has one sample. \n",
    "oneSVMs = []\n",
    "\n",
    "blah = np.vstack((flag_features[:,0], flag_features[:,9]))\n",
    "\n",
    "for i in range(len(flag_features[0])):\n",
    "    svmlist = []\n",
    "    for j in range(1, len(flag_features[0])):    \n",
    "        _svm = svm.LinearSVC(penalty='l2', loss='hinge', max_iter = 20000, tol=0.001)\n",
    "        _svm.fit(np.vstack((flag_features[:,i], flag_features[:,j])), [1,0])\n",
    "        svmlist.append(_svm)\n",
    "    oneSVMs.append(svmlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes - each individual SVM takes less time to train. But, we have to train a lot more of them (18,741). \n",
    "def getOVOPrediction(oneSVMs, x, labels):\n",
    "    predictions = []\n",
    "    for svmlist in oneSVMs:\n",
    "        predictionlist = []\n",
    "        for _svm in svmlist:\n",
    "            predictionlist.append(_svm.predict(x))\n",
    "        predictions.append(predictionlist.count([1]))\n",
    "    return labels[predictions.index(max(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_predictions = []\n",
    "for i in range(len(flag_features[0])):\n",
    "    flag = flag_features[:,i].reshape(1,29)\n",
    "    prediction = getOVOPrediction(oneSVMs, flag, flag_names)\n",
    "    flag_predictions.append(prediction)\n",
    "    print(\"Predicted: \" + prediction + \"\\tActual: \" + flag_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(predictions, actual):\n",
    "    #Based on 0-1 loss metric\n",
    "    correct = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == actual[i]:\n",
    "            correct += 1\n",
    "    return round(correct/len(actual),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One vs. All Accuracy\n",
    "print(Accuracy(OVA_flag_predictions, flag_names))\n",
    "\n",
    "#One vs. One Accuracy\n",
    "print(Accuracy(flag_predictions, flag_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that one vs. all classification actually had more success than one vs. one classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file2 = pd.read_csv(\"flag.data\")\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = file2.values\n",
    "labels = file2.values[:,10]\n",
    "data = file2.values[:,1:10]\n",
    "data = np.column_stack((data,file2.values[:,11:17]))\n",
    "data = np.column_stack((data,file2.values[:,18:28]))\n",
    "data = np.array(data,dtype=float)\n",
    "datat = data.T      #------PCA Steps Seen in Second Wine--------\n",
    "meandata = datat.mean(axis = 1)\n",
    "meanmat = np.tile(meandata.reshape(datat.shape[0],1),[1,datat.shape[1]])\n",
    "center = datat - meanmat\n",
    "U, s, Vh = np.linalg.svd(center)\n",
    "U2 = U[:,0:2]\n",
    "x = U2.T@center\n",
    "test = x[:,:40].T\n",
    "testlabels = labels[:40]\n",
    "traindata = x[:,40:].T\n",
    "trainlabels = labels[40:]\n",
    "plt.title(\"PCA Data Distribution\")\n",
    "plt.scatter(x.T[np.where(labels==0),0],x.T[np.where(labels==0),1],c='r',marker='o',label = '1')\n",
    "plt.scatter(x.T[np.where(labels==1),0],x.T[np.where(labels==1),1],c='g',marker='s',label = '2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data shown on graph using PCA.  It uses a similiar process to Wine Classification Dataset 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = knn(5,traindata,test,trainlabels)\n",
    "d = knnerror(g,testlabels)\n",
    "print(\"kNN error using PCA is %\",d*100,\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test[np.where(g==0),0],test[np.where(g==0),1],c='r',marker='^')\n",
    "plt.scatter(test[np.where(g==1),0],test[np.where(g==1),1],c='g',marker='^')\n",
    "plt.scatter(traindata[np.where(trainlabels==0),0],traindata[np.where(trainlabels==0),1],c='r',marker='o')\n",
    "plt.scatter(traindata[np.where(trainlabels==1),0],traindata[np.where(trainlabels==1),1],c='g',marker='o')\n",
    "plt.title('PCA KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = folds(data,5,35)\n",
    "t = folds(labels,5,35)\n",
    "a,b = bestk([1,5,10,20,50],5,j,t)\n",
    "print(\"The best value of k using crossvalidation is\",a,\"and the error associated is %\",b*100,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag Gaussian Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_data=[];\n",
    "with open('flag.txt') as f:    \n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        flag_data.append(data[0].split(\",\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the column that contains a boolean value describing whether or not the color red is in the flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "land=[]\n",
    "red=[]\n",
    "for g in range (len(flag_data)):\n",
    "    red.append(flag_data[g][10])\n",
    "    land.append(flag_data[g][1])\n",
    "red=np.asarray(red)\n",
    "land=np.asarray(land)\n",
    "print(red.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the numerical values from the dataset and concatence the data together to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=np.asarray([i[1:10] for i in flag_data])\n",
    "data2=np.asarray([i[11:17] for i in flag_data])\n",
    "data3=np.asarray([i[18:28] for i in flag_data])\n",
    "data=np.hstack((data1,data2))\n",
    "data=np.hstack((data,data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 194 data samples and 25 attributes for each data sample. This is relatively small amount of data samples, and could potientally lead to high classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "print(data.shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the Sci-kit learn GuassianNB Bayes function. We will plug our training data into model.fit() function and we will make predictions using the model.predict() function. The way GaussianNB works is that it iterates through every possible class of the output and calculates the mean and the standard deviation of ech feature of the training data that corresponds to that class. The mean is given by the sum of the elements divided by the total number of elements in the training set. The standard deviation is is given by taking each data sample and subtracting the mean of that feature and taking the square of the result. This value is summed for all of the data samples for each feature and is then  divided by the number of training samples per feature. This gives us the variance. Finally we take the square root of the data to obtain the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above equation the mu represents the mean and the sigma^2 represents the standard deviation. x represents the sample that we are testing. We will plug into this equation for each test sample to obtain the probability that it belongs to each class. The feature with the greatest probability will be the prediction for the data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "train_fold=folds(data,5,39)\n",
    "test_fold=folds(red,5,39)\n",
    "# for h in range(5):\n",
    "#     print(train_fold[h].shape)\n",
    "#     print(test_fold[h].shape)\n",
    "    \n",
    "splitdata=np.asarray([train_fold[0],train_fold[1],train_fold[2],train_fold[3],train_fold[4]])  \n",
    "splitlabels=np.asarray([test_fold[0],test_fold[1],test_fold[2],test_fold[3],test_fold[4]])  \n",
    "\n",
    "def cross_validation(k, splitdata, splitlabels):\n",
    "    z = np.zeros(k)\n",
    "    final = [];\n",
    "    for i in range(k):\n",
    "        training_data = np.concatenate(np.delete(splitdata, i,0),axis=0)\n",
    "        train_labels = np.concatenate(np.delete(splitlabels, i,0),axis=0)\n",
    "        test_data = splitdata[i]\n",
    "        test_labels = splitlabels[i]    \n",
    "        model.fit(training_data.astype(float),train_labels.astype(float))\n",
    "        predicted= model.predict(test_data.astype(float))\n",
    "        acc = predicted-test_labels.astype(float)\n",
    "        z[i]=np.count_nonzero(acc)/acc.size\n",
    "        final = np.concatenate((final,predicted))\n",
    "    return np.mean(z),final    \n",
    "    \n",
    "acc,l=cross_validation(5,splitdata,splitlabels)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have performed k-fold cross validation for classification iwth k=5. In this case, there were 4 folds used for testing and 1 fold used for testing. With this implementation each data sample was only used once for testing.\n",
    "The accuracy of the model is 0.45. This is relatively low since the size of our data was relatively low as well. we only had 194 x 25 data samples altogether. This made it difficult for our alogrithm to be successful. Also it may be possible for their to be little correlation between the data and the output value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order for the classification to improve, we may try to predict a different feature and determine if that has improved results. Also, we may want to obtain more data to improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automobiles Dataset Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will Perform LASSO Regression in an attempt to predict the price of an automobile given its different attributes\n",
    "#Load dataset\n",
    "cars = np.array(pd.read_csv('cars.data', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#Not all entries are numerical, such as make, fuel type, number of doors, body style, etc\n",
    "\n",
    "#make\n",
    "make = {'alfa-romero' : 0, 'audi' : 1, 'bmw' :  2, 'chevrolet' : 3, 'dodge' : 4, 'honda' : 5, \n",
    "'isuzu' : 6, 'jaguar' : 7, 'mazda' : 8, 'mercedes-benz' : 9, 'mercury' : 10, \n",
    "'mitsubishi' : 11, 'nissan' : 12, 'peugot' : 13, 'plymouth' : 14, 'porsche' : 15, \n",
    "'renault' : 16, 'saab' : 17, 'subaru' : 18, 'toyota' : 19, 'volkswagen' : 20, 'volvo' : 21}\n",
    "#fuel type\n",
    "fuel_type = {'diesel' : 0, 'gas' : 1}\n",
    "#aspiration\n",
    "aspiration = {'std' : 0, 'turbo' : 1}\n",
    "#num doors\n",
    "num_doors = {'four' : 0, 'two' : 1}\n",
    "#body style \n",
    "body_style = {'hardtop' : 0, 'wagon' : 1, 'sedan' : 2, 'hatchback' : 3, 'convertible' : 4}\n",
    "#drive-wheels\n",
    "drive = {'4wd' : 0, 'fwd' : 1, 'rwd' : 2}\n",
    "#engine-location\n",
    "eng_loc = {'front': 0, 'rear': 1}\n",
    "\n",
    "\n",
    "#engine type\n",
    "eng_type = {'dohc' : 0, 'dohcv' : 1, 'l' : 2, 'ohc' : 3, 'ohcf' : 4, 'ohcv' : 5, 'rotor' : 6}\n",
    "#num cylinders\n",
    "num_cyl = {'eight' : 0, 'five' : 1, 'four' : 2, 'six' : 3, 'three' : 4, 'twelve' : 5, 'two' : 5}\n",
    "#fuel system\n",
    "fuel_sys = {'1bbl' : 0, '2bbl' : 1, '4bbl' : 2, 'idi' : 3, 'mfi' : 4, 'mpfi' : 5, 'spdi' : 6, 'spfi' : 6}\n",
    "\n",
    "#For the attribute of normalized-losses, certain samples lack this attribute. In place of a number is a question sign\n",
    "#For simplicity, I'll replace that question mark with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace ?'s\n",
    "for i in range(len(cars[:,0])):\n",
    "    if cars[i,1] == '?': \n",
    "        cars[i,1] = 0\n",
    "    else:\n",
    "        cars[i,1] = int(cars[i,1])\n",
    "\n",
    "#replace make\n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,2] = make[cars[i,2]]\n",
    "\n",
    "#replace fuel type\n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,3] = fuel_type[cars[i,3]]\n",
    "    \n",
    "#replace aspiration\n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,4] = aspiration[cars[i,4]]\n",
    "    \n",
    "#replace num_doors. There are some question marks here. By default I'll give it four doors\n",
    "for i in range(len(cars[:,0])):\n",
    "    if cars[i,5] == '?':\n",
    "        cars[i,5] = 'four'\n",
    "    cars[i,5] = num_doors[cars[i,5]]\n",
    "\n",
    "#replace body style\n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,6] = body_style[cars[i,6]]\n",
    "    \n",
    "#replace drive\n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,7] = drive[cars[i,7]]\n",
    "    \n",
    "#replace engine location\n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,8] = eng_loc[cars[i,8]]\n",
    "\n",
    "#replace engine type\n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,14] = eng_type[cars[i,14]]\n",
    "\n",
    "#replace num cylinders    \n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,15] = num_cyl[cars[i,15]]\n",
    "    \n",
    "#replace fuel system    \n",
    "for i in range(len(cars[:,0])):\n",
    "    cars[i,17] = fuel_sys[cars[i,17]]\n",
    "    \n",
    "#There are still ?s in the data. We'll iterate through the entire array and make them 0s for simplicity\n",
    "\n",
    "for i in range(len(cars)):\n",
    "    for j in range(len(cars[0])):\n",
    "        if cars[i,j] == '?':\n",
    "            cars[i,j] = 0\n",
    "        else:\n",
    "            cars[i,j] = float(cars[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll perform the task of LASSO regression. First, we need to calculate the regularization parameter, lamba (or alpha in the case of sklearn's LASSO regression tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, discretize lambda\n",
    "\n",
    "lam = np.linspace(0.1, 10, 30)\n",
    "\n",
    "#Then, using each lamba, perform k fold CV and pick the lambda that performed the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of k-fold cross validation for LASSO \n",
    "\n",
    "def kfoldRegression(k, x, y, l): #k = num folds, x = data, y = prices, l = lamda value \n",
    "    x_split = np.array_split(x, 5)\n",
    "    y_split = np.array_split(y, 5)\n",
    "    models = []\n",
    "\n",
    "    for i in range(0,k):\n",
    "        test = x_split[i]\n",
    "        train_labels = np.hstack([y_split[j] for j in range(0,k) if j != i])\n",
    "        temp = [x_split[j] for j in range(0,k) if j != i]\n",
    "        train = np.vstack(temp)\n",
    "        reg_model = linear_model.Lasso(alpha=l)\n",
    "        reg_model.fit(train, train_labels)\n",
    "        models.append(reg_model)    \n",
    "    \n",
    "    errors = []\n",
    "    for model in models:\n",
    "        predictions = model.predict(x)\n",
    "        error = 0\n",
    "        for i in range(len(predictions)):\n",
    "            error += abs(predictions[i] - y[i])**2\n",
    "        error /= len(predictions)\n",
    "        errors.append(error)\n",
    "        \n",
    "    return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape data\n",
    "prices = cars.transpose()[-1]\n",
    "car_data = cars.transpose()[0:len(prices)].transpose()\n",
    "\n",
    "#Determine optimal lambda\n",
    "lambda_errors = []\n",
    "for l in lam:\n",
    "    lambda_errors.append(kfoldRegression(5, car_data, prices, l))\n",
    "\n",
    "#This is our lambda (alpha) value\n",
    "lambda_optimal = lam[lambda_errors.index(min(lambda_errors))]\n",
    "print(\"optimal lambda value: \" + str(lambda_optimal))\n",
    "\n",
    "'''\n",
    "reg_model = linear_model.Lasso(alpha=0.1)\n",
    "reg_model.fit(car_data, prices)\n",
    "\n",
    "price_predictions = reg_model.predict(car_data)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(prices)):\n",
    "    error += abs(prices[i] - price_predictions[i])\n",
    "print(error)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can train the LASSO regression model\n",
    "LASSO = linear_model.Lasso(alpha=lambda_optimal)\n",
    "LASSO.fit(car_data, prices)\n",
    "#Make predictions\n",
    "predictions = LASSO.predict(car_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prices)\n",
    "plt.plot(predictions)\n",
    "error = 0\n",
    "for i in range(len(prices)):\n",
    "    error = abs(prices[i] - predictions[i])**2\n",
    "error/=len(prices)\n",
    "\n",
    "print(\"error: \" + str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automobile Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file2 = pd.read_csv(\"imports-85.data\")\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = file2.values\n",
    "totalnew = [x for x in total if '?' not in x] #data has missing values called '?'. This gets rid of those values.\n",
    "totalnew = np.asarray(totalnew)\n",
    "prices = totalnew[:,-1]\n",
    "data1 = totalnew[:,9:13]#data we are using \n",
    "data2 = totalnew[:,18:24]#data we are using\n",
    "datatotal = np.column_stack((data1,data2))\n",
    "datatotal = datatotal.astype(np.float)\n",
    "prices = prices.astype(np.float)#values we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folds(data,k,split): #split is what size split you want\n",
    "    n = []\n",
    "    num1 = 0\n",
    "    num2 = split\n",
    "    for i in range(k-1):\n",
    "        n.append(data[num1:num2])\n",
    "        num1 = num2\n",
    "        num2 = num2 + split\n",
    "    n.append(data[num1:])\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=folds(datatotal,5,31)\n",
    "p=folds(prices,5,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(x,y,test):\n",
    "        wfull = np.linalg.inv(x.T@x)@x.T@y\n",
    "        return test@wfull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares regression finds the best w values in the equation y=wx +b. We can simplify this to y = wb since b can be appended to the w and x parameters. The solution we are using is  w=(xTx)−1xTyw=(xTx)−1xTy  which is implemented in least_squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validationleastsquares(k, splitdata, splitlabels,lam=None):\n",
    "    z = np.zeros(k)\n",
    "    final = [];\n",
    "    for i in range(k):\n",
    "        training_data = np.concatenate(np.delete(splitdata, i,0),axis=0)\n",
    "        train_labels = np.concatenate(np.delete(splitlabels, i,0),axis=0)\n",
    "        test_data = splitdata[i]\n",
    "        test_labels = splitlabels[i]\n",
    "        y_tested = least_squares(training_data.astype(float),train_labels.astype(float),test_data.astype(float))\n",
    "        z[i] = error_rate(y_tested.astype(float),test_labels.astype(float))\n",
    "        final = np.concatenate((final,y_tested))\n",
    "    return np.mean(z),final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cross validation leastsquares, each fold will act once as the test data and return a mean squared error. Then, it will return the mean error of all the calculated errors along with there computed values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(trained,actual):\n",
    "    w = np.zeros(trained.shape[0])\n",
    "    for i in range(trained.shape[0]):\n",
    "        w[i] = (trained[i] - actual[i])**2\n",
    "    return np.mean(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate is mean square error rate.  This means the error is the squared difference between each data value and the actual value.  Then, we take the mean of all these values and return it.  This is useful as we won't have any negative value in our error and we want to measure the error in the distance between the points and actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = cross_validationleastsquares(5,o,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(prices, b)\n",
    "plt.title(\"Measured vs Predicted\")\n",
    "plt.xlabel(\"Measured\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.plot(np.linspace(0,30000,50000),np.linspace(0,30000,50000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above measures Least Squared where the x axis are the true values and the y axis are the predicted values. The least squared algorithm is used to find the best fit line. The line represents y=x which represents accuracy of the classifier. The closer the line is to each datapoint, the better the accuracy of the classifier. In our dataset, the measured and predicted points do follow the trend of y=x but contains outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The error for least squared is\",a,\"which is the mean squared error.  The number is relative to the values seen by the datapoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automobile Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_reg(x,y,test,lam):\n",
    "    wfull = np.linalg.inv(x.T@x + lam*np.identity(x.shape[1]))@x.T@y\n",
    "    return test@wfull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are implementing ridge regression which uses lamda to imprive the result of least squares regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_ridge(k, splitdata, splitlabels,lam=None):\n",
    "    z = np.zeros(k)\n",
    "    final = [];\n",
    "    for i in range(k):\n",
    "        training_data = np.concatenate(np.delete(splitdata, i,0),axis=0)\n",
    "        train_labels = np.concatenate(np.delete(splitlabels, i,0),axis=0)\n",
    "        test_data = splitdata[i]\n",
    "        test_labels = splitlabels[i]\n",
    "        if(lam):\n",
    "            y_tested = ridge_reg(training_data.astype(float),train_labels.astype(float),test_data.astype(float),lam)\n",
    "        else:    \n",
    "            y_tested = least_squares(training_data.astype(float),train_labels.astype(float),test_data.astype(float))\n",
    "        z[i] = error_rate(y_tested.astype(float),test_labels.astype(float))\n",
    "        final = np.concatenate((final,y_tested))\n",
    "    return np.mean(z),final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses cross validation to determine the best lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrmain(k,splitdata,splitlabels,lam):\n",
    "    newsplitdata = np.delete(splitdata, 0,0)\n",
    "    newsplitlabels = np.delete(splitlabels, 0,0)\n",
    "    errlam = np.zeros(lam.size)\n",
    "    for i in range(lam.size):\n",
    "        errlam[i] = (cross_validation_ridge(k-1,newsplitdata,newsplitlabels,lam[i]))[0]\n",
    "    bestlam = lam[np.argmin(errlam)]\n",
    "    print(bestlam)\n",
    "    return cross_validation_ridge(k,splitdata,splitlabels,bestlam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrmain,rrtestans = rrmain(5,o,p,np.linspace(0,10,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best lamda value is 10. This was determined by discretizing the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(prices, rrtestans)\n",
    "plt.title(\"Measured vs Predicted Ridge Regression\")\n",
    "plt.xlabel(\"Measured\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.plot(np.linspace(0,30000,50000),np.linspace(0,30000,50000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plotted data is close to the line x=y, so the ridge regression algorithm is properly functioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
